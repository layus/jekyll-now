<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Layus' short musings - Posts tagged 'build systems'</title>
    <link href="https://blog.layus.be/tags/build%20systems.atom" rel="self" />
    <link href="https://blog.layus.be" />
    <id>https://blog.layus.be/tags/build%20systems.atom</id>
    <author>
        <name>layus</name>
        <email>layus.on@gmail.com</email>
    </author>
    <updated>2021-06-25T00:00:00Z</updated>
    <entry>
    <title>Reproducibility killed the frankenbuild</title>
    <link href="https://blog.layus.be/posts/2021-06-25-frankenbuilds.html" />
    <id>https://blog.layus.be/posts/2021-06-25-frankenbuilds.html</id>
    <published>2021-06-25</published>
    <updated>2021-06-25T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <p>They have been around for far too long. It’s about time to tackle those pesky frankenbuilds. Coined in 2016 by Esfahani et al. the term describes “builds where outputs from different build jobs can combine in inconsistent ways due to cache re-use”.</p>
<p>Let’s start with an example scenario for the problem. Imagine a build systems that runs a benchmark of some program and then processes the results into a human friendly html summary. Both results get added to the cache, but the benchmark results get later evicted from the cache. On the next build, the cache miss forces a new execution from the cache, and uploads the new version to the now empty cache slot. All the cache entries contain a valid build output, but is left in an inconsistent state where the html summary corresponds to a benchmark that is not available anymore. When the builder downloads the cached html report, it ends up in an incorrect build state, where the report is not up-to-date with the benchmark, despite both having been generated correctly from the specification.</p>
<p>A frankenbuild is an inconsistent build state where an output β that was generated based on an intermediate output α is used together with a different version α’ of α due to cache substitution. This violates the necessary condition for the build to be correct, as the output β is not up-to-date with respect to its concrete input α’. The situation can happen in several ways, but only under some circumstances.</p>
<ol type="1">
<li>A build output α needs some variability that escapes the vigilance of the build system.</li>
<li>There also needs to be some other build output β that depends on α and exposes some of its variability.</li>
<li>Then the cache needs to store under the same cache key all the versions of β, generated from any variation of α.</li>
<li>And finally α’, a variation of α, needs to be generated and used wrongly in conjunction with the original β.</li>
</ol>
<p><img src="../images/frankenbuild_context.png" class="image-large center" /></p>
<p>This last point needs clarification as it covers a range of situations. A build system that gets a cache miss for α will regenerate a new α’. But two builds running in parallel can race to fill the cache, and each get only one of their two outputs stored, taking α’ from one and β from the other. Situations involving several caches also hide traps, as the two caches may have been populated separately.</p>
<p>Frankenbuilds are real threats to build theoretical correctness, but chiefly they could end up in long hair-pulling sessions where before finding that the two involved inputs are incompatible. As would be the case when you debug an executable with similar but incompatible debug symbols. And the infrequency of these events makes them even more ominous, because these are not part of the mental model of the users facing the issue. Fortunately, there are many ways in which they can be eradicated, or mitigated.</p>
<h2 id="cache-keys-are-the-key">Cache keys are the key</h2>
<p>One way to look at this issue is that there is confusion on the validity of output <span class="math inline"><em>β</em></span>. Being generated from the successive tasks <span class="math inline"><em>A</em></span> and <span class="math inline"><em>B</em></span> is not sufficient to make it a correct build output for any output of task <span class="math inline"><em>A</em></span>. A provenance relation needs to be respected to ensure the consistency of the full build. The confusion arises when cache keys do not encode this provenance. This is the case with build systems like Buck and Nix who computes cache keys based on the transitive closure of build instructions, and not the bits of intermediate results. This shows one weakness of these indexing schemes.</p>
<p>We call such a keying scheme “intensional”, as the keys define what the content should be. For example, the content under key <code>B(A(src))</code> is the result of applying task <span class="math inline"><em>B</em></span> on the output of task <span class="math inline"><em>A</em></span>, itself called with the said initial <code>src</code> sources.</p>
<div class="scroll-wrapper">
<pre><code>cache[&quot;B(A(src))&quot;] = β      # but also β&#39;
cache[&quot;A(src)&quot;] = α</code></pre>
</div>
<p>When cache keys for β include a digest of the actual α output, it becomes impossible to retrieve the β based on a differing α’. We call this keying mechanism “extensional”, as it computes computes a digest of the content of all the inputs of a task, and also of the definition of the task. The cache keys record more closely what objects are, and less the process that builds them.</p>
<div class="scroll-wrapper">
<pre><code>cache[&quot;B(α)&quot;]   = β
cache[&quot;B(α&#39;)&quot;]  = β&#39;
cache[&quot;A(src)&quot;] = α</code></pre>
</div>
<p>This is in essence the reasoning described by the authors of CloudBuild: “To avoid this issue, BuildCloud­includes the input’s content bag identity when computing a target’s CacheKey.” Faced with the issue, they augmented their cache keys with digests of concrete inputs, effectively switching to another class of build systems.</p>
<p>This new keying mechanism takes into accounts the exact inputs used during the build comes with strong implications. The value of α must be know to be able to compute the key to lookup β. This forces to serialize the queries to the cache along a dependency path and thus forces a bottom-up realisation of the build tree (i.e. a top-down realisation on the production tree presented here).</p>
<p>This impact is mitigated during incremental builds because digests can be cached locally. In that case an incremental build requires only an incremental set of queries to the cache. And yet, some companies reported that these constant back and forth from the builder to the server where a bottleneck for large builds. They had to focus on cache and network speed, and had to use tricks like a special cache api that returns the digest of α without returning the full content, or dedicated build farm APIs that handle the full build graph to resolve the keys close to the cache server, reducing round-trips <span class="citation" data-cites="BuildGraph">[@BuildGraph]</span>.</p>
<h2 id="intensional-advantages-intentional-advantages">Intensional advantages, intentional advantages</h2>
<p>As we have seen, extensional keying effectively prevents frankenbuilds, but comes with some constraints. Conversely, one may say that frankenbuilds arise due to the use of intensional keying schemes. And yet, Buck and Nix do rely on this flawed scheme, and there seems to be no traction in these projects to change in the foreseeable future. Let’s see why these projects use this keying scheme, and how they cope with its limitations. We will focus on Nix for it is the project we know best, but we can surmise that Buck follows approximately the same logic.</p>
<p>The reason why Nix uses intensional caches is that they allow to query for the presence of the final result directly, as the query can be constructed solely from the sources without any intermediate output. When a nix user wants to install a package, they are mostly interested in that package and the ones it depends upon at <em>run time</em>. They do not want to download the compiler that was used to compile it, nor the bootstrap compiler that was used to compile the compiler, and which are both <em>build time</em> dependencies of their packages.</p>
<p>Such incomplete builds where only a subset of the outputs are materialized are called shallow builds. They are not restricted to package managers like Nix. Materializing the whole set of intermediate outputs in a large codebase is often unnecessary and can waste a lot of local storage. When a developer edits a single file, they only need the intermediate products along the build branch that includes their file to reconstruct the final output.</p>
<p>Intensional keying make it faster to perform shallow builds as the final result can be queried immediately. On cache miss, it’s dependencies can be queried just as easily, until all the cached elements are found. The build can the proceed to materialize the missing outputs. This contrasts with key schemes, where the full closure of dependencies must be fetched (or at least their digest) in order to query the cache for the final binary.</p>
<p>As for frankenbuilds, they turn out to be theoretically possible, but not encountered in practice. There is only a single official cache for nix packages (i.e. nix build outputs). And only one build infrastructure is trusted to populate it. There is therefore no race to fill cache buckets. As for cache eviction, no package has ever been evicted (yet) from the central package cache of nix packages. With these two aspects, the main cache of packages is always consistent.</p>
<p>There remains scenarios where a use could end-up with frankenbuilds, for example when they build locally several packages not yet in the official cache (<span class="math inline"><em>α</em>′</span>), and later download more packages (<span class="math inline"><em>β</em></span>) from the cache. With the advent of multiple caches <span class="citation" data-cites="Cachix">[@Cachix]</span>, populated and evicted differently, the issue may see a revival of interest.</p>
<h2 id="provenance-and-the-build-paths">Provenance and the build paths</h2>
<p>A recent initiative in the Nix world, the “content addressed store”, may eradicate frankenbuilds definitively. The changes encompass and are motivated by way more than frankenbuilds, but let’s explore how they address this particular issue.</p>
<p>In the process of designing CloudBuild, Esfahani et al. came with the concept of “provenance” relation. It captures the idea that a build can only be known to be correct if all the outputs are known to have been built from the other outputs that are materialized in the same build.</p>
<p>Instead of storing the provenance information in the cache keys, an alternative is to adjoin it to the cache values.</p>
<div class="scroll-wrapper">
<pre><code>cache[&quot;B(A(src))&quot;] = (β&#39;, from B(α&#39;))
cache[&quot;A(src)&quot;] = (α, from A(src))</code></pre>
</div>
<p>That way, downloaded entries can be checked for consistency with respect to the provenance relation. But it also means that the cache is less useful, as it may contain contradictory results. in this situation, a solution may be to store sets of cache entries under the same key.</p>
<div class="scroll-wrapper">
<pre><code>cache[&quot;B(A(src))&quot;] = { (β, from B(α), (β&#39;, from B(α&#39;)) }
cache[&quot;A(src)&quot;] = { (α, from A(src)) }</code></pre>
</div>
<p>This solution is undesirable in practice, because all the entries must be downloaded and tested in sequence, and may still end up on a cache miss if none matches.</p>
<p>The content addressed store initiative works around this issue, by maintaining a content addressed cache of build outputs.</p>
<div class="scroll-wrapper">
<pre><code>cache[&quot;B(A(src))&quot;] = β&#39;
cache[&quot;A(src)&quot;] = α

cache[&quot;α&quot;]  = (α,  from A(src))
cache[&quot;α&#39;&quot;] = (α&#39;, from A(src))
cache[&quot;β&quot;]  = (β,  from B(α))
cache[&quot;β&#39;&quot;] = (β&#39;, from B(α&#39;))</code></pre>
</div>
<p>In this fashion, the provenance chain can be reconstructed from the cache, if all the entries are still present. Clients of the cache can thus avoid materializing frankenbuilds. This convoluted scheme is still vulnerable to other issues and inefficiencies, but not frankenbuilds.</p>
<h2 id="the-ultimate-razor">The ultimate razor</h2>
<p>Looking back at the necessary conditions for frankenbuilds to happen, we have seen that we can work around condition 4. by being careful not to let frankenbuilds happen in the cache, with centralised caches and restricted population strategies, or by tagging cache entries with provenance information. Condition 3. can be falsified by switching to another keying scheme, but that is a huge change in the build system design. Conditions 2. and 1. are also worth investigating.</p>
<p>Condition 2 states that there must be a second output that depends on the first, variable one, and that it must expose its variability. As build systems with no inter dependant tasks are way more limited than their inter dependant counterparts, it is not of great use. And while it is worth noting that there exists build system tasks that do not expose the variability in their dependencies, it is impossible to assert that for all the tasks of a general purpose build system.</p>
<p>Finally, condition 1 is quite interesting. It states that frankenbuilds cannot happen with tasks that exhibit no variability. While that property can again not be enforced nor verified for the tasks of a general purpose build system, hunting down variability reduces the chances of materializing frankenbuilds, and further reduces the chances of ever incurring its negative effects.</p>
<p>The property of a task with no variability s called reproducibility. A task is perfectly reproducible when all it’s executions yield the same output, bit for bit. Reproducibility cannot be guaranteed, but it can be tested, and examples of identical results in various conditions, as well as the absence of any variation in the long run can give some confidence that the task is indeed reproducible.</p>
<p><img src="../images/frankenbuild_reproducible.png" class="image-medium center" /></p>
<p>Reproducibility is the holy grail of build systems. It makes caching perfectly efficient, gives perfect confidence in binary outputs, and trivially reduces provenance tracking. It’s no wonder that binary package repositories strive to eradicate nondeterminism in their tasks. Linux distributions even started the reproducible build initiative <span class="citation" data-cites="RBI">[@RBI]</span> to share experience and good practice in reproducible package builds.</p>
<h2 id="conclusion">Conclusion</h2>
<p>From the niche frankenbuild issue, we have explored a large variety of build systems designs, and in particular nontrivial cache keying schemes. We have seen the conditions to create a monstrous frankenbuild, and various solutions to work around them when one really wants to live in the world of intensional keying schemes. Finally, we had a quick look at reproducibility, the ever escaping ideal in the world of build systems. Reproducibility, to paraphrase Terry Pratchett, didn’t just kill the frankenbuild, it threw it in the river with lead weights tied to its feet.</p>
</article>
]]></summary>
</entry>
<entry>
    <title>A Tour of the Build Systems Galaxy</title>
    <link href="https://blog.layus.be/posts/2021-01-22-build-systems-tour.html" />
    <id>https://blog.layus.be/posts/2021-01-22-build-systems-tour.html</id>
    <published>2021-01-22</published>
    <updated>2021-01-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <p>In the <a href="./2020-11-09-what-are-build-systems.html">last episode</a>, I presented a concise definition of build systems. I designed it so that it includes as many approaches as possible to the problem. I fantasized this episode as a trip along the border drawn by this definition. The idea was to explore curious build systems, from those that barely fit the definition to the mainstream ones, passing by little known outsiders and niche designs.</p>
<p>As it turns out, the article was already long enough after exploring quite a few implementations. It turns out that in my quest to start with simple tools, they all happened to share a common feature: the build specification amounts to a single script. None of the build systems presented here require an explicit list of tasks inputs, nor any other kind of upfront information about the commands that have to be executed. For now, let’s refer to these as script-based build systems.</p>
<p>The name “script-based” build systems does not exist yet. It is introduced here for convenience. They are sometimes called “forward” build systems, but I prefer the more technical and evocative term of “imperative” build systems, for reasons I elaborate at the end of this article.</p>
<p>So here is a tour of all the <em><abbr title="choose one !">{script-based, forward, imperative}</abbr></em> build systems that I am aware of.</p>
<h1 id="scripting-build-systems">Scripting build systems</h1>
<h2 id="down-to-the-basics">Down to the basics</h2>
<p>The minimal build system often comes as a surprise: it is a single script. Either bash, bat, or any scripting language. Wikipedia’s definition for scripting languages fits perfectly in <a href="./2020-11-09-what-are-build-systems.html">our definition</a> of build systems. We reproduce it here for it is terser than the ECMAScript spec referenced as a source:</p>
<blockquote>
<p>A scripting or script language is a programming language for a special run-time environment that automates the execution of tasks;<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> the tasks could alternatively be executed one-by-one by a human operator.</p>
<div class="cite">
<p>– <a href="https://en.wikipedia.org/wiki/Scripting_language">Scripting Language</a>, in <cite>Wikipedia</cite></p>
</div>
<div style="clear: both;">

</div>
</blockquote>
<p>Everything is in there. A scripting language <em>automates</em> the <em>execution</em> of <em>tasks</em>. They can definitely be used as build systems, provided that the tasks are used to process and produce some information.</p>
<p>Here is a trivial build system for a no less trivial application written in C.</p>
<div class="scroll-wrapper">
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="co">#! /usr/bin/env bash</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a><span class="fu">gcc</span> lib.c -o lib.o</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a><span class="fu">gcc</span> app.c -o app.o</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a><span class="fu">gcc</span> app.o lib.o -lm -o app</span></code></pre></div>
</div>
<p>This build system works correctly, but leaves a lot of room for optimisation. It is nonetheless a perfectly valid build system. For this small project it is easy to setup, easy to maintain, and easy to install as the script language used is assumed to be installed by default in the developer environment.</p>
<h2 id="dedicated-tasks-runners">Dedicated tasks runners</h2>
<p>This basic ability of running a sequence of tasks is already interesting enough in itself that it received it’s own dedicated name: a task runner. The best examples are Grunt and Gulp that both target JavaScript code bases. Here is a sample Gruntfile, the name of Grunt configuration files, from <a href="https://gruntjs.com/sample-gruntfile">the project official website</a>.</p>
<div class="scroll-wrapper">
<div class="sourceCode" id="cb2"><pre class="sourceCode js"><code class="sourceCode javascript"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a>module<span class="op">.</span><span class="at">exports</span> <span class="op">=</span> <span class="kw">function</span>(grunt) {</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a>  grunt<span class="op">.</span><span class="fu">initConfig</span>({</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a>    <span class="dt">jshint</span><span class="op">:</span> {</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a>      <span class="dt">files</span><span class="op">:</span> [<span class="st">&#39;Gruntfile.js&#39;</span><span class="op">,</span> <span class="st">&#39;src/**/*.js&#39;</span><span class="op">,</span> <span class="st">&#39;test/**/*.js&#39;</span>]<span class="op">,</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a>    }</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a>  })<span class="op">;</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true"></a>  grunt<span class="op">.</span><span class="fu">loadNpmTasks</span>(<span class="st">&#39;grunt-contrib-jshint&#39;</span>)<span class="op">;</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true"></a>  grunt<span class="op">.</span><span class="fu">registerTask</span>(<span class="st">&#39;default&#39;</span><span class="op">,</span> [<span class="st">&#39;jshint&#39;</span>])<span class="op">;</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true"></a>}<span class="op">;</span></span></code></pre></div>
</div>
<p>Task runners elaborate on scripts by providing specific support for build systems. Grunt and Gulp come with progress report during execution, and convenient tools for declaring the tasks. As the example above suggests, generic tasks can be shared and reused in several projects. They can be further specialized with configuration options. Of course custom, hand-written tasks can still be described. For open-source build systems, the set of available tasks, modules or plugins typically grows with the size of the community using it.</p>
<p>These tools also have an implicit understanding of what task outputs and inputs are. Files in this case. But hey will nevertheless support tasks with no input, nor output. For example a task that starts, restarts or stop a web server works fine<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Tests also fit this model as tasks without output. A failure of these halts the build, just as any other would.</p>
<p>The order of the tasks must still be specified manually, as they are executed in the order in which they are specified. Grunt users must ensure that all the intermediate files are referenced correctly.</p>
<p>Finally, tasks are named, which makes it easy to construct a tree of tasks, or run only a named subset of them. The example only has a <code>'default'</code> task to run, but bigger projects can have many more and compose them.</p>
<p>While these tools use none of the advanced algorithms we will describe later, they fit their environment. In the context of JavaScript web development there is no long compilation phase. But files are often required to go through several transformation steps (concatenation, minification, uglyfication, compression) and then several operations need to be automated (testing, deployment, restarting of server, refreshing ow browser pages, etc.). These tasks are hard if not impossible to capture in the strict models used by other tools.</p>
<p>Because tasks are quick, it is okay to run them unconditionally. And because it is hard to automatically determine which one can correctly be skipped, this is often the only safe option.</p>
<h2 id="when-you-are-already-up-to-date">When you are already up-to-date</h2>
<p>Memoize and Fabricate are our two next curiosities in the galaxy of build systems. Conceptually, they are the same thing because Fabricate presents itself as a rewrite of Memoize that also supports Windows<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. They speed up build scripts by skipping tasks whose inputs are unchanged since their previous execution. The specificity of these tools is that they trace the execution of the tasks at a low-level to extract all file accesses. The method is thus applicable to a wide range of tasks for a wide range of projects independently of the language or tools used.</p>
<p>Technically, two discoveries happen on a task execution. The set of dependencies are learned, and their content is fingerprinted. Note that the order of the tasks is still fixed by the script. Tasks can only be skipped, but not reordered by the build system. This caching technique enable incremental building, where only a subset of the tasks are executed to “refresh” a build. The build systems presented before did not have this property.</p>
<h3 id="scripts-and-command-wrappers">Scripts and command wrappers</h3>
<p>Fabricate and memoize have two related modes of execution. They can be invoked as single command wrappers, and as script libraries. In wrapper mode, every command invocation must be prefixed by the wrapper to take effect.</p>
<div class="scroll-wrapper">
<div class="sourceCode" id="cb3"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="co">#!/bin/sh</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a><span class="ex">memoize.py</span> gcc -c file1.c</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a><span class="ex">memoize.py</span> gcc -c file2.c</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a><span class="ex">memoize.py</span> gcc -o program file1.o file2.o</span></code></pre></div>
</div>
<p>The script mode comes as a convenient way to use the wrapper when programming in a language for which bindings exists, or directly in the language in which the wrapper tool has been written. In the case of these two tools, python is the only choice.</p>
<div class="scroll-wrapper">
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a><span class="im">from</span> fabricate <span class="im">import</span> <span class="op">*</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a>sources <span class="op">=</span> [<span class="st">&#39;program&#39;</span>, <span class="st">&#39;util&#39;</span>]</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a><span class="kw">def</span> build():</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true"></a>    <span class="bu">compile</span>()</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true"></a>    link()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true"></a><span class="kw">def</span> <span class="bu">compile</span>():</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true"></a>    <span class="cf">for</span> source <span class="kw">in</span> sources:</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true"></a>        run(<span class="st">&#39;gcc&#39;</span>, <span class="st">&#39;-c&#39;</span>, source<span class="op">+</span><span class="st">&#39;.c&#39;</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true"></a><span class="kw">def</span> link():</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true"></a>    objects <span class="op">=</span> [s<span class="op">+</span><span class="st">&#39;.o&#39;</span> <span class="cf">for</span> s <span class="kw">in</span> sources]</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true"></a>    run(<span class="st">&#39;gcc&#39;</span>, <span class="st">&#39;-o&#39;</span>, <span class="st">&#39;program&#39;</span>, objects)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true"></a><span class="kw">def</span> clean():</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true"></a>    autoclean()</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true"></a>main()</span></code></pre></div>
</div>
<p>The core feature is the <code>run()</code> command that executes the given system command with the wrapper in place. But the script mode can also alleviate boilerplate as is the case in the above example with a <code>main()</code> function that automatically derives available targets from functions names, and support for cleaning generated files with <code>autoclean()</code></p>
<p>Truth be told, there is no essential difference between the script and wrapper mode because both need to identify commands to be executed with the wrapper, and the script mode does no much more than deferring to the same logic as the wrapper mode.</p>
<h2 id="command-wrappers-for-everything">Command wrappers for everything</h2>
<p>More generally, any command wrapper can be seen as minimalist build system handling one command, and can be further threaded into build scripts to profit from their features. As is the case with ccache and sccache.</p>
<p>The name CCache stands for Compiler Cache. A wrapper able to perform caching of compiler invocations. It best supports gcc, clang and cuda and thus targets mostly C/C++ compilation tasks. SCCache is a separate tool to support sharing of those caches across the network. The name stands for Shared CCache.</p>
<p>These tools elaborate on the idea of Fabricate by caching build results instead of tracking if existent files are up-to-date. This allows to substitute the output of tasks that were part of older executions of the build system. With enough care, these outputs can be shared across build directories, across users on the same machine, or even across the network.</p>
<p>There exists other commands wrappers like distcc, that distributes the wrapped commands within a cluster of machines to speed up the compilation. Icecream does the same with a central scheduling server.</p>
<p>As a final command wrapper, we should mention recc which brings together remote (aka distributed) execution and remote caching.</p>
<p>Command wrappers allow to gain extra features with minimal changes to existing build specifications. They can be used as is, or as an intermediate step to estimate the potential gains of their respective features before migrating to an advanced build system, potentially not script-based.</p>
<h2 id="can-we-get-faster">Can we get faster</h2>
<p>All the build systems seen up to now execute tasks in the script order. This does not prevent some parallelism to take place when the script is thus written, but it forces upon the build system users the necessary verification that the script is written in the correct order.</p>
<p>Rattle tries to bypass this limitation by introducing speculative execution. Rattle is an experimental build system based on tracing commands execution to skip identical invocations (like fabricate) and provide caching (like a generalized ccache for any system command). Rattles tries to compete with advanced build systems while retaining the simplicity of script-based build descriptions.</p>
<p>To further speed up linear build scripts, Rattle takes the risk of wasting ressources and speculates on future commands to execute them anticipatively. Advantages and pitfalls with speculation are well known in computer science. The impact in the case of Rattle has been studied in the introducing paper <span class="citation" data-cites="spall-2020">[@spall-2020]</span>.</p>
<p>The correctness of anticipated executions is guaranteed by the system-level tracing on the commands, which ensures accurate information on inputs and outputs of the commands and allow to detect changes to inputs of eagerly executed commands.</p>
<p>By tracing execution, the build system may however discover issues that where not apparent during the execution of the build script. The implementors of Rattle discovered build specification containing two commands writing to the same same file. This shows how collected information about the build specification can discover and help enforce correct results.</p>
<h1 id="script-based-build-systems-and-beyond">Script based build systems, and beyond</h1>
<p>From the bare execution of a series of commands in an executable script to the speculative execution of cached tasks execution, we see that a build script can get various improvements. First performance wise, with incremental builds, caching, distributed caching and remote execution. Also with respect to usability with time estimates (the so called progress bars) and simplified tasks description. And finally regarding correctness issues when race conditions and outputs variations are made visible by the tooling.</p>
<p>If we step back a bit, to look at the full list of build systems presented here, we observe they are not the usual tools one would associate with build systems. Some did not gain traction, some are still experimental, some are better described by their specific function than as build systems on their own. Their lower common denominator, the build script, is usually conceived as a draft waiting to be replaced by a proper build system. They are however perfectly valid build systems.</p>
<p>What they have in common is the way they encode the tasks that must be executed: as a sequence of instructions. They describe the commands to be executed in an imperative way, as opposed to the declarative paradigm where commands are described as data. In the imperative script style, the commands cannot be listed without executing the script. And the build system requires no a priori information on the tasks to perform correctly.<br />
It is precisely this lack of information on the tasks that limits the optimisations that can be successfully applied during the execution of the task set. This is why one needs to ressort to speculative execution to take advantage of parallelism beyond what the script prescribes.</p>
<p>In the literature, the term “forward build system” is also used to describe these imperative build systems. The term seems to have appeared within Shake source code, but we could find no definition of it. A possible interpretation is that declarative build systems configuration allow the build system to work backward from the final goals and build the dependencies transitively, while imperative build systems configurations only work in one direction, forward, the normal direction of execution for scripts.</p>
<p>The interest of imperative build systems reside in their simplicity. There is no need to learn a specification (aka configuration) language. There is no need to explicit or even know the dependencies of the tasks. All that is needed is to reproduce the set of commands that where typically entered manually.</p>
<p>Again, the trade-off resides at the information you are willing to encode. Imperative scripts encode less exploitable information about the tasks, which makes them shorter and easier to write. But as the software project becomes bigger and bigger, providing more information enables build systems to use more efficient optimisations, and to provide more correctness guarantees on the final result. At the expense of more maintenance on the build specification.</p>
<p>We can only surmise that it is because imperative build systems tend to be used in small projects that they did not receive a lot of attention. Despite their relative discretion, they are numerous and diverse, and enabled this introduction to techniques and algorithms specific to build systems in general.</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>https://tc39.es/ecma262/#sec-overview<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>https://gruntjs.com/sample-gruntfile<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>“It was inspired by Bill McCloskey’s make replacement, memoize, but fabricate works on Windows as well as Linux.” in Fabricate’s <a href="https://github.com/brushtechnology/fabricate#user-content-fabricate">README.md</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</article>
]]></summary>
</entry>
<entry>
    <title>Am I a build system ?</title>
    <link href="https://blog.layus.be/posts/2020-11-09-what-are-build-systems.html" />
    <id>https://blog.layus.be/posts/2020-11-09-what-are-build-systems.html</id>
    <published>2020-11-09</published>
    <updated>2020-11-09T00:00:00Z</updated>
    <summary type="html"><![CDATA[<article>
    <p>In the quest of defining what is a build system, we start by looking at existing definitions. We had to cast the net far and wide for there are few formal attempts at defining this widely used concept. Here are the four that we found.</p>
<blockquote>
<p>The build system is the set of build specification files used by the CI infrastructure (and developers) to generate project deliverables like binaries, libraries or packages […] from the source code. Moreover, the build system automates many other activities, such as test execution and sometimes deployment.</p>
<p>A build system typically consists of a configuration layer and a construction layer. The configuration layer is used to select which features should be compiled and included in the resulting deliverables, as well as which build tools (e.g., compilers, interpreters) are necessary to compile those features. Once configured, the construction layer is used to specify the build tool invocations that are required to generate deliverables from source code. Since these build tool invocations are order-dependent […], a key responsibility of the construction layer is to invoke build tools while respecting their dependencies.</p>
<p>[…]</p>
<div class="cite">
<p>– <cite>Bram Adams and Shane McIntosh</cite>, <a href="http://mcis.polymtl.ca/publications/2016/fose.pdf#page=4">Modern Software Engineering in a Nutshell</a>.</p>
</div>
<div style="clear: both;"/>

</blockquote>
<blockquote>
<p>Build automation is the process of automating the creation of a software build and the associated processes including: compiling computer source code into binary code, packaging binary code, and running automated tests.</p>
<div class="cite">
<p>– Build Automation, <cite><a href="https://en.wikipedia.org/w/index.php?title=Build_automation&amp;oldid=996141938">Wikipedia</a></cite></p>
</div>
<div style="clear: both;"/>

</blockquote>
<blockquote>
<p>Build systems automate the execution of repeatable tasks, at a scale from individual users up to large organisations. (p.2)</p>
<p>A build system takes a task description, a target key, and a store, and returns a new store in which the target key and all its dependencies have up-to-date values. (p.9)</p>
<div class="cite">
<p>– <cite>Andrey Mokhov, Neil Mitchell and Simon Peyton Jones</cite>, <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/03/build-systems.pdf">Build systems à la carte</a></p>
</div>
<div style="clear: both;"/>

</blockquote>
<blockquote>
<p>In this paper, a build system is any piece of software that provides facilities for constructing and parsing the DAG which represents the dependencies among files in a software project. (p.3)</p>
<p>This paper is not focused on the aspect of building software related to configuration options as would typically be handled by software such as autoconf or kconfig, even though some of these features have been introduced into build systems billed as replacements for make (which itself does not have such features built-in). When the build system is invoked, it will input the DAG and current filesystem state, and output a new DAG and/or files that represent the output of the build. (p.3)</p>
<div class="cite">
<p>– <cite>Mike Shal</cite>, <a href="http://gittup.org/tup/build_system_rules_and_algorithms.pdf#page=3">Build System Rules and Algorithms</a></p>
</div>
<div style="clear: both;"/>

</blockquote>
<p>Build systems are a key part in modern software engineering pipeline[nutshell]. They grew organically from the need to encode knowledge about and automate all the tasks involved in the transformation of software sources into binary executables, test results and other artifacts that may be needed further down the development pipeline. The name “build system” itself seems to come from the idea that programs need to be built from their sources before finding any use. But there exists other tools which encounter similar problems and solve them using comparable algorithms. For example spreadsheets build their cells values from formulas. And some package mangers can build sets of interdependent packages from custom description formats.</p>
<p>In our quest to define build systems, we would like to liberally include disparate software systems provided that their internal design choices can be compared. We would like to include single bash scripts that are used as build systems as well as task runners that do not call themselves build systems, and also various odd, corner case build automation tool such as [fabricate], [stroll] or [portage].</p>
<p>We identified key concepts pertaining to build systems by reviewing four definitions found in the literature.</p>
<ul>
<li><p>Build systems serve a purpose of <strong>automation</strong>. They can be trusted in their operation and require minimal if any human assistance to deliver their result. Good build systems should operate quietly and reliably<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p></li>
<li><p>Automation outlines the implicit existence of <strong>tasks</strong> to be automated. A build system supervises the execution of a delimited set of tasks. Build systems differ in the kind of tasks they expect and handle correctly, but they always expect tasks with a limited lifespan. Tools that manage the execution of long-standing processes such as web servers fall in the category of monitors and services managers. The completion of a build systems signals the end of all the managed tasks.</p></li>
<li><p>This is because build systems view tasks as means to and end: producing build <strong>artefacts</strong>. Build systems supervise a bipartite graph of build tasks and build products, also know as a data flow graph<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. The nature of the data produced, and thus also consumed, by build system tasks encompasses env variables, strings, full docker images, software packages and files. The latter being the first that comes to mind when thinking about canonical build systems.</p></li>
<li><p>Tasks are related to each other through <strong>dependencies</strong> on their productions. Build system have the responsibility to enforce and maintain a consistent execution order. While most build system expect a partial order, some are capable of handling preorders under certain assumptions. From a dependency graph perspective it means that most build systems will expect a directed acyclic graph of dependencies but that some provide support for dependency graphs with cycles.</p></li>
<li><p>In some cases, build systems are not provided with the <strong>dependency graph</strong> upfront. To simplify the management of tasks interdependencies, some support automatic discovery of that graph dynamically. As much as the underlying graph of dependencies may be used as a reasoning tool, it does not have to be reified by build systems to execute the tasks.</p></li>
<li><p>Build systems <strong>performance</strong>, particularly at large scale, may be important in certain contexts. We think however that there is no performance threshold or implementation optimisation that should exclude a given tool from entering the family of build systems. For an inefficient sorting algorithm is still a sorting algorithm, the same applies to build systems.</p></li>
</ul>
<p>This comparison with sorting algorithms hints at something running deeper. Build systems are tools defined by the similar problem they solve. We could consider a build system any tool that implements a scheduling algorithm for a set of tasks. Like sorting algorithms there are many variations depending on special properties of the input. Unlike sorting algorithms however, build system algorithms face <em>a lot</em> of variations in the input formats, expectations, and different implementations. </p>
<h3 id="definition-of-build-system">Definition of build system</h3>
<p>From all the aspects we forged the following definition.</p>
<blockquote>
<p>Build systems are software components that automate the generation of software products by scheduling the execution of a set of potentially interdependent processes.</p>
</blockquote>
<p>By this definition, we limit ourselves to the software world. Car assembly lines for example are not included, even though they do automate the production of products. It is important because physical artifacts come with extra constraints on their production. While, a newly generated file can overwrite the previous one, it is not the case for cars.</p>
<p>Further on, the emphasis is put on software products, rather that on the processes that produce them. These processes are a means to an end, and not the subject of the build system. With this wording we exclude software systems devoted to start and monitor services. <code>Systemd</code>, Erlang monitors or the venerable <code>init</code> are out of scope because their focus is not on producing something, but on running something, and keeping it running.</p>
<p>Nevertheless, the definition insists on tasks as the core issue to tackle. These tasks have interdependencies that must be taken into account, and are the sole way to produce the desired products. Task managers like <code>grunt</code> are included in this definition because that is exactly what they do. But as we may see in a future article, the outputs they produce consists more of effects on a system and not software products <em>per se</em>. That makes them a bit apart amongst build systems</p>
<p>Finally, all the subtlety and the complexity of writing <em>“good”</em> build systems resides in the way they schedule the execution of the processes. The most important aspect of which is <em>incremental execution</em>. The technique consists in <em>not</em> running a task if it is not needed. Or conversely, running only tasks needed to regenerate outdated products.</p>
<p>In future episodes, we will explore what makes a good schedule, how the choice of schedules is constrained by the upfront information about the processes, as well as the information that can be collected during and after their execution.</p>
<p>This design space is interspersed with existing implementations that come with peculiar choices and specific solutions according to their main concern. The variety of approaches to this single problem is captivating. And that they all work only under a specific set of assumptions or requirements on their execution environment is thrilling.</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Ironically, this may explain why they are unloved[ALC]. They only get noticed when they are in the way, because it means that they do not live up to the expectations of their users.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>A Formal Definition of Data Flow Graph Models KRISHNAM KAVI, BILLP BUCKLES, ANDU NARAYANBHAT http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.589.9759<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</article>
]]></summary>
</entry>

</feed>
